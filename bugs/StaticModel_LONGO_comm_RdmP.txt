
    
model {
        
  # priors
  ## priors for P
  ## depth effect
  for (k in 1:nspec) {
     for (i in 1:2){ # Implicitly define alpha of depth as a vector
       alpha.depth[k,i] ~ dunif(0,1)
       intercept.depth[k,i] <- logit (alpha.depth[k,i])
    #alpha0 [k] ~ dunif (0,1)
    #intercept.p[k] <- logit(alpha0[k]) 
     }
  }
   
  ## alpha1 - effect of time on detection p
  # it also comesfrom the community
  for (k in 1:nspec) {
      alpha1.time[k] ~ dnorm (mu.time[k],tau.time[k]) 
      mu.time[k] ~ dnorm(0, 0.001)
      tau.time[k] <- 1/(sigma.time[k]*sigma.time[k])
      sigma.time[k] ~ dunif(0,10)
  }
  
  ## random effect for video
  for (k in 1:nspec){
     alpha0[k] ~ dunif (0,1)
     lalpha0[k] <- logit (alpha0[k])
     sd.p[k] ~ dunif (0,10) ## sd of p on logit scale
     tau.p[k] <- pow (sd.p[k],2)## p precision on logit scale
  }
  
  # one estimate per transect
  for (k in 1:nspec) {
     for (j in 1:nocca){
       logit (intercept.p [k,j]) <- lp [k,j]
       lp[k,j] ~ dnorm (lalpha0[k],tau.p[k])
     }
  }

  ## occupancy priors
  for (k in 1:nspec) {
  #  for (j in 1:nreg) {
        beta0 [k] ~ dunif (0,1)
        intercept.psi [k] <- logit(beta0[k])
    # }
   }

  ## regression coefficient
  for (k in 1:nspec) {
  #  for (j in 1:nreg){
        beta1[k] ~ dnorm (mu.int[k],tau.mu[k])  
  #     ## priors for them
        mu.int[k] ~ dnorm(0, 0.001)
        tau.mu[k] <- 1/(sigma.int[k]*sigma.int[k])
        sigma.int[k] ~ dunif(0,10)
  #   }
  }

  # Ecological submodel: Define state conditional on parameters
  for (k in 1:nspec) {
     for(i in 1:nsite){    ## occupancy model
        
        z [i,k] ~ dbern(psi[i,k])
                
        ## This keeps the program on the track
        psi[i,k]<-max(0.00001,min(0.99999, psi0[i,k]))
    
        logit(psi0 [i,k]) <- intercept.psi[k] + beta1 [k]* coral [i]# intercept.psi[k,reg[i]] + beta1 [k,reg[i]]
                                                  
        }
   }
        
   # # # # # # # #  # # # # 
   ####### observation model
                
   for (k in 1:nspec) {
                   
      for (n in 1:nobs) { ## loop over replicated surveys
                      
         y [n,k] ~ dbern(muY[site[n], occa[n],k])
         muY [site[n], occa[n],k] <- z[site[n],k] * p[k,n]
         logit (p[k,n]) <-  intercept.depth[k,prof[n]]+alpha1.time[k]*time[n] + intercept.p[k, occa[n]]
          
       }

    }
        
        
    ##############################################################
    #                      Goodness of fit                       #
    ##############################################################
    #       (based on posterior predictive distributions)       #
    #############################################################
    # Draw a replicate data set under the fitted model
    for (k in 1:nspec) {
       for (n in 1:nobs){
          yrep[n,k] ~ dbern(muYrep[site [n], occa[n],k])
          muYrep [site [n], occa[n],k] <- z[site [n],k]*p[k,n]
       }
    }
    
    # Compute detection frequencies for observed and replicated data
    ## the first loop is used to extract data for each site    
    ## The outside function sum is used to aggregate data
    
    for (k in 1:nspec) {
      for (i in 1:nsite) {
        for (n in 1:nobs) {
    
          y.prov [i,n,k] <- ifelse (site[n] == i, y [n,k],0)## provisorious data
          yrep.prov [i,n,k] <- ifelse (site[n] == i, yrep [n,k],0)## provisorious data
        
           }
    
      detfreq [i,k] <- sum (y.prov[i,,k]) ## aggregate data
      detfreqrep [i,k] <- sum (yrep.prov[i,,k]) ## aggregate data
    
     }
   }
    
  # Expected detection frequencies under the model
  for (k in 1:nspec) {
     for (n in 1:nobs){
        tmp[n,k] <- z[site[n],k] * p[k,n]
     }
   }
    
  ## the first loop is used to extract data for each site    
  ## The outside function sum is used to aggregate data
  for (k in 1:nspec) {
      for (i in 1:nsite) {
         for (n in 1:nobs) {
    
            E.prov [i,n,k] <- ifelse (site[n] == i, tmp [n,k],0) ## provisorious data
            
        }
    
        E [i,k] <- sum (E.prov[i,,k]) ## aggregate data
    
     }
   }
    
  # discrepancy statistics
  for (k in 1:nspec) {
     for (i in 1:nsite) {
    
        # Chi-square and Freeman-Tukey discrepancy measures
        # ..... for actual data set
        x2Closed[i,k] <- pow((detfreq[i,k] - E[i,k]),2) / (E[i,k]+e)
        ftClosed[i,k] <- pow((sqrt(detfreq[i,k]) - sqrt(E[i,k])),2)
        # ..... for replicated data set
        x2repClosed[i,k] <- pow((detfreqrep[i,k] - E[i,k]),2) / (E[i,k]+e)
        ftrepClosed[i,k] <- pow((sqrt(detfreqrep[i,k]) - sqrt(E[i,k])),2)
       }
   }
    
  # Add up Chi-square and FT discrepancies and compute fit stat ratio
  # (closed part)
  for (k in 1:nspec) {
     Chi2Closed[k] <- sum(x2Closed[1:nsite,k])
     FTClosed[k] <- sum(ftClosed[1:nsite,k])
     Chi2repClosed[k] <- sum(x2repClosed[1:nsite,k])
     FTrepClosed[k] <- sum(ftrepClosed[1:nsite,k])
     Chi2ratioClosed[k] <- Chi2Closed[k] / Chi2repClosed[k]
     FTratioClosed[k] <- FTClosed[k] / FTrepClosed[k]
        
     ##
     # Derived parameters: Sample and population occupancy, growth rate and turnover
     mutot[k] <- sum(psi[1:nsite,k]) ## expected number of occupied sites (infinite sample)
     n.occ[k] <- sum(z[1:nsite,k]) ## finite sample
     mean.p[k] <- mean (p[k,])
  }
  
  ## richness
  for (i in 1:nsite) {
     
     rich[i] <- sum (z[i,])
     
  }
     
} # end of the model
        

    
